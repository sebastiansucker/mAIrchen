services:
  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: mairchen-app
    ports:
      - "80:80"
    env_file:
      - ../.env
    environment:
      # AI Provider (openai, ollama-cloud, ollama-local)
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      # OpenAI-compatible API (OpenAI, Mistral, Together AI, Anyscale, OpenRouter, etc.)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.mistral.ai/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-mistral-small-latest}
      # Ollama Cloud
      - OLLAMA_API_KEY=${OLLAMA_API_KEY}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      # Ollama Local
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434/v1}
      # CORS-Sicherheit: Nur diese Origins d√ºrfen zugreifen
      # In Produktion durch echte Domain ersetzen, z.B. https://mairchen.de
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost,http://localhost:80}
      # Rate Limiting & Cost Control
      - RATE_LIMIT_PER_IP=${RATE_LIMIT_PER_IP:-10}  # Anfragen pro Stunde pro IP
      - GLOBAL_DAILY_LIMIT=${GLOBAL_DAILY_LIMIT:-1000}  # Max Anfragen pro Tag
      - MAX_STORY_LENGTH=${MAX_STORY_LENGTH:-15}  # Max Minuten
      - MAX_DAILY_COST=${MAX_DAILY_COST:-5.0}  # Max Kosten pro Tag in Euro
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}  # DEBUG, INFO, WARNING, ERROR, CRITICAL
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
