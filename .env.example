# AI Provider Konfiguration
# Optionen: openai, ollama-cloud, ollama-local
AI_PROVIDER=openai

# OpenAI-Compatible API Konfiguration (default: Mistral, aber funktioniert mit jedem OpenAI-kompatiblen Endpoint)
# Beispiele: Mistral, OpenAI, Together AI, Anyscale, OpenRouter, Azure OpenAI, etc.
OPENAI_API_KEY=your-key-here
OPENAI_BASE_URL=https://api.mistral.ai/v1
OPENAI_MODEL=mistral-small-latest

# Ollama Cloud Konfiguration (wenn AI_PROVIDER=ollama-cloud)
# OLLAMA_API_KEY=your-key-here
# OLLAMA_MODEL=gpt-oss:120b-cloud

# Ollama Lokal Konfiguration (wenn AI_PROVIDER=ollama-local)
# OLLAMA_BASE_URL=http://OLLAMA-IP:11434/v1
# OLLAMA_MODEL=gemma3:latest

# Logging Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# Für Produktion: INFO oder WARNING
# Für Debugging: DEBUG
LOG_LEVEL=INFO